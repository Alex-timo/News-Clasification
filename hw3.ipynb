{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**step 1: install torchdata**"
      ],
      "metadata": {
        "id": "Yhej6IBBY16C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove PyTorch first -- torchdata depends on a nightly version of PyTorch."
      ],
      "metadata": {
        "id": "91xM24xWGNHR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh2efPhIFqkY",
        "outputId": "b1faf66e-7e5f-44fb-861b-75f95f262c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 1.11.0\n",
            "Uninstalling torch-1.11.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.7/dist-packages/caffe2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torch-1.11.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torch-1.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgIXNuunGrh2",
        "outputId": "a05be401-d9cc-4f8b-abce-85701ee361ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install a PyTorch nightly binary. Pick a different one depending on the CUDA version:"
      ],
      "metadata": {
        "id": "FC2lFybHG2NS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For CUDA 10.2\n",
        "# >>> pip install --pre torch -f https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html\n",
        "# For CUDA 11.1\n",
        "# >>> pip install --pre torch -f https://download.pytorch.org/whl/nightly/cu111/torch_nightly.html\n",
        "# For CPU-only build\n",
        "# >>> pip install --pre torch -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\n",
        "\n",
        "# We're going to use a CPU-only binary\n",
        "!pip install --pre torch -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5NpNuUMG3lx",
        "outputId": "32df3b6e-282d-43f5-9903-81729996f3aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cpu/torch-1.13.0.dev20220521%2Bcpu-cp37-cp37m-linux_x86_64.whl (189.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 189.0 MB 24 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.13.0.dev20220521+cpu which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.13.0.dev20220521+cpu which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.13.0.dev20220521+cpu which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.13.0.dev20220521+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install torchdata."
      ],
      "metadata": {
        "id": "dFOR5-kCHe8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --user \"git+https://github.com/pytorch/data.git\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yApIw0geHff1",
        "outputId": "1ba4849f-9158-4416-9f5b-7840b3e4f98a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/pytorch/data.git\n",
            "  Cloning https://github.com/pytorch/data.git to /tmp/pip-req-build-4ge2jr3_\n",
            "  Running command git clone -q https://github.com/pytorch/data.git /tmp/pip-req-build-4ge2jr3_\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata==0.4.0a0+12cfaf8) (2.23.0)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 32.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchdata==0.4.0a0+12cfaf8) (1.13.0.dev20220521+cpu)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>1.11.0->torchdata==0.4.0a0+12cfaf8) (4.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata==0.4.0a0+12cfaf8) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata==0.4.0a0+12cfaf8) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata==0.4.0a0+12cfaf8) (2021.10.8)\n",
            "Building wheels for collected packages: torchdata\n",
            "  Building wheel for torchdata (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchdata: filename=torchdata-0.4.0a0+12cfaf8-py3-none-any.whl size=87747 sha256=d344fee6093e5f822fd20a7f9ec5daa2300db9e9f89d0cd8b9610116097bfb29\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8_2uhnqc/wheels/a9/4f/7a/6edd9e915eb0cf0d88565db0f14b9b2b83e5f9f56c192042ad\n",
            "Successfully built torchdata\n",
            "Installing collected packages: urllib3, portalocker, torchdata\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed portalocker-2.4.0 torchdata-0.4.0a0+12cfaf8 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When this is done, you may need to restart the colab runtime to complete the installation. Go to Runtime > Restart runtime**\n",
        "\n",
        "Finally, run some sanity checks."
      ],
      "metadata": {
        "id": "UQlPl6DdMx8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchdata.datapipes.iter import HttpReader\n",
        "URL = \"https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\"\n",
        "ag_news_train = HttpReader([URL]).parse_csv().map(lambda t: (int(t[0]), \" \".join(t[1:])))\n",
        "agn_batches = ag_news_train.batch(2).map(lambda batch: {'labels': [sample[0] for sample in batch],\\\n",
        "                                      'text': [sample[1].split() for sample in batch]})\n",
        "batch = next(iter(agn_batches))\n",
        "print(batch)\n",
        "assert batch['text'][0][0:8] == ['Wall', 'St.', 'Bears', 'Claw', 'Back', 'Into', 'the', 'Black']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGD0FeKyMzWp",
        "outputId": "4997e167-7a76-4d50-fcd8-8b2698d708b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'labels': [3, 3], 'text': [['Wall', 'St.', 'Bears', 'Claw', 'Back', 'Into', 'the', 'Black', '(Reuters)', 'Reuters', '-', 'Short-sellers,', 'Wall', \"Street's\", 'dwindling\\\\band', 'of', 'ultra-cynics,', 'are', 'seeing', 'green', 'again.'], ['Carlyle', 'Looks', 'Toward', 'Commercial', 'Aerospace', '(Reuters)', 'Reuters', '-', 'Private', 'investment', 'firm', 'Carlyle', 'Group,\\\\which', 'has', 'a', 'reputation', 'for', 'making', 'well-timed', 'and', 'occasionally\\\\controversial', 'plays', 'in', 'the', 'defense', 'industry,', 'has', 'quietly', 'placed\\\\its', 'bets', 'on', 'another', 'part', 'of', 'the', 'market.']]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchtext==0.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "m55NJ_5ZM7kY",
        "outputId": "d72b2f74-5d09-4a98-9e02-9027467a2c0e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 25.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.0)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.1 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /root/.local/lib/python3.7/site-packages (from requests->torchtext==0.10.0) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0.dev20220521+cpu\n",
            "    Uninstalling torch-1.13.0.dev20220521+cpu:\n",
            "      Successfully uninstalled torch-1.13.0.dev20220521+cpu\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.12.0\n",
            "    Uninstalling torchtext-0.12.0:\n",
            "      Successfully uninstalled torchtext-0.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.4.0a0+12cfaf8 requires torch>1.11.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**restart here again**"
      ],
      "metadata": {
        "id": "VL_vfqWrZP6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step 2: access to the raw dataset iterators**"
      ],
      "metadata": {
        "id": "BwFzO00YZuEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "16dCS9BMNash"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext.datasets import AG_NEWS\n",
        "train_iter = iter(AG_NEWS(split='train'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYhQn1zINdtA",
        "outputId": "ad3e74cc-d980-4319-d1c2-a645b280d5b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train.csv: 29.5MB [00:00, 85.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(train_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwVfUV8aNgvw",
        "outputId": "aece9783-fbf3-42e2-cb3a-aaa1c5937cff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step 3: Prepare data processing pipelines**"
      ],
      "metadata": {
        "id": "M2MCY1tSZh9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "train_iter = AG_NEWS(split='train')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "RfhyY0VCNlAy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab(['here', 'is', 'an', 'example'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYHegpSwNqi4",
        "outputId": "2497d392-de62-41f0-a565-2ac705e0bfc2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[475, 21, 30, 5297]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x) - 1"
      ],
      "metadata": {
        "id": "-zaKGmYANt7R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline('here is the an example')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKOxYIdWN06J",
        "outputId": "54424894-0611-49c0-dbc0-de4a8146da20"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[475, 21, 2, 30, 5297]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_pipeline('10')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXHTx7QTN3CB",
        "outputId": "6ad213c5-9b7a-4ae7-9561-ccda9217ac51"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step 4: Generate data batch and iterator**"
      ],
      "metadata": {
        "id": "p_M4dOlnZ-9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_label, _text) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
        "\n",
        "train_iter = AG_NEWS(split='train')\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "KvpNgezIN8dp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step 5: Define the model**"
      ],
      "metadata": {
        "id": "z5-L98evaNzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "metadata": {
        "id": "EhoVhsx_N_8o"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step 5: Initiate an instance**"
      ],
      "metadata": {
        "id": "fHUgWrNiaYAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = AG_NEWS(split='train')\n",
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ],
      "metadata": {
        "id": "HssOQCRAODUQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step 6: Define functions to train the model and evaluate results.**"
      ],
      "metadata": {
        "id": "fqOy53_xajnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predicted_label = model(text, offsets)\n",
        "        loss = criterion(predicted_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predicted_label = model(text, offsets)\n",
        "            loss = criterion(predicted_label, label)\n",
        "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ],
      "metadata": {
        "id": "vUnG_60UOHeh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step 7: Split the dataset and run the model**"
      ],
      "metadata": {
        "id": "dD0PAhlJaxlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64 # batch size for training\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "train_iter, test_iter = AG_NEWS()\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = \\\n",
        "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
        "\n",
        "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVCohp8cOLlx",
        "outputId": "9bacf99c-4233-400b-8c4d-d8910e6d260f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test.csv: 1.86MB [00:00, 74.5MB/s]                  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 1782 batches | accuracy    0.685\n",
            "| epoch   1 |  1000/ 1782 batches | accuracy    0.855\n",
            "| epoch   1 |  1500/ 1782 batches | accuracy    0.875\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 16.29s | valid accuracy    0.882 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 1782 batches | accuracy    0.897\n",
            "| epoch   2 |  1000/ 1782 batches | accuracy    0.900\n",
            "| epoch   2 |  1500/ 1782 batches | accuracy    0.905\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 15.26s | valid accuracy    0.885 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 1782 batches | accuracy    0.914\n",
            "| epoch   3 |  1000/ 1782 batches | accuracy    0.914\n",
            "| epoch   3 |  1500/ 1782 batches | accuracy    0.916\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 15.57s | valid accuracy    0.901 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 1782 batches | accuracy    0.927\n",
            "| epoch   4 |  1000/ 1782 batches | accuracy    0.923\n",
            "| epoch   4 |  1500/ 1782 batches | accuracy    0.922\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 15.36s | valid accuracy    0.901 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 1782 batches | accuracy    0.932\n",
            "| epoch   5 |  1000/ 1782 batches | accuracy    0.931\n",
            "| epoch   5 |  1500/ 1782 batches | accuracy    0.926\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 15.67s | valid accuracy    0.902 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 1782 batches | accuracy    0.937\n",
            "| epoch   6 |  1000/ 1782 batches | accuracy    0.933\n",
            "| epoch   6 |  1500/ 1782 batches | accuracy    0.934\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time: 15.79s | valid accuracy    0.902 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 1782 batches | accuracy    0.939\n",
            "| epoch   7 |  1000/ 1782 batches | accuracy    0.940\n",
            "| epoch   7 |  1500/ 1782 batches | accuracy    0.937\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time: 25.18s | valid accuracy    0.900 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 1782 batches | accuracy    0.952\n",
            "| epoch   8 |  1000/ 1782 batches | accuracy    0.952\n",
            "| epoch   8 |  1500/ 1782 batches | accuracy    0.950\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time: 15.65s | valid accuracy    0.906 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 1782 batches | accuracy    0.953\n",
            "| epoch   9 |  1000/ 1782 batches | accuracy    0.955\n",
            "| epoch   9 |  1500/ 1782 batches | accuracy    0.953\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time: 15.49s | valid accuracy    0.906 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 1782 batches | accuracy    0.953\n",
            "| epoch  10 |  1000/ 1782 batches | accuracy    0.952\n",
            "| epoch  10 |  1500/ 1782 batches | accuracy    0.956\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time: 15.39s | valid accuracy    0.907 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step 8: Evaluate the model with test dataset**"
      ],
      "metadata": {
        "id": "gSe5JeCPa27p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Checking the results of test dataset.')\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print('test accuracy {:8.3f}'.format(accu_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huLCKAXdO6S-",
        "outputId": "8ae82835-65d7-434f-e54c-0ec36afaa1f9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking the results of test dataset.\n",
            "test accuracy    0.905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step 9: Test on a random news**"
      ],
      "metadata": {
        "id": "vB5EVjOJa7jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ag_news_label = {1: \"World\",\n",
        "                 2: \"Sports\",\n",
        "                 3: \"Business\",\n",
        "                 4: \"Sci/Tec\"}\n",
        "\n",
        "def predict(text, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1\n",
        "\n",
        "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
        "    enduring the season’s worst weather conditions on Sunday at The \\\n",
        "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
        "    considering the wind and the rain was a respectable showing. \\\n",
        "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
        "    was another story. With temperatures in the mid-80s and hardly any \\\n",
        "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
        "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
        "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
        "    was even more impressive considering he’d never played the \\\n",
        "    front nine at TPC Southwind.\"\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, text_pipeline)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEni_FX0O9v-",
        "outputId": "2a3888ae-e980-47ac-d5b1-b267698f02bd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a Sports news\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_text_str2 = \"A tornado left 43 people injured as it cut a path of destruction through several towns in western Germany, police said. \\\n",
        "Officers in the city of Paderborn said the tornado ripped off roofs and debris was strewn around for kilometres. \\\n",
        "Ten people have serious injuries and one woman's life is in danger, they said. \\\n",
        "A 38-year-old man also died in severe storms which lashed the region on Friday.\"\n",
        "\n",
        "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str2, text_pipeline)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9rrpLufPlF4",
        "outputId": "1a4dbcc1-db4f-4274-921d-2acaded74f12"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a World news\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_text_str3 = \"Canada says it will ban two of China's biggest telecoms equipment makers from working on its 5G phone networks. \\\n",
        "The restrictions against Huawei and ZTE were announced by the country's industry minister on Thursday. \\\n",
        "Francois-Philippe Champagne says the move will improve Canada's mobile internet services and protect the safety and security of Canadians. \\\n",
        "But Huawei Canada said it was disappointed by the decision, which it said was political.\"\n",
        "\n",
        "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str3, text_pipeline)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-GpoH73QTZD",
        "outputId": "d2df16ff-b1b4-43c5-be21-866a3f2265b9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a Sci/Tec news\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_text_str4 = \"The lure of making a quick buck has always attracted young people to invest in risky assets. \\\n",
        "For Generation Z, it is the volatility - and the decentralised nature - of digital assets such as cryptocurrency and NFTs which appeals. \\\n",
        "But they are unregulated, meaning there is little investor protection. \\\n",
        "All my friends were talking about [cryptocurrency] so one day I just decided why not just jump in and see if I can make some money, says 20-year-old Paxton See Tow. \\\n",
        "All he needed was his phone and trading thousands of dollars' worth of assets was only a click away.\"\n",
        "\n",
        "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str4, text_pipeline)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W06VVITFRLmE",
        "outputId": "32cd15a5-0176-4ba1-b5da-820d0e2d9d3b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a Business news\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_text_str5 = \"Automakers from Tesla to Rivian to Cadillac are hiking prices on their electric vehicles \\\n",
        "amid changing market conditions and rising commodity costs, specifically for key materials needed for EV batteries.\\\n",
        "Battery prices have been declining for years, but that may be about to change. \\\n",
        "One firm projects a sharp increase in demand for battery minerals over the next \\\n",
        "four years that could push the price of EV battery cells up by more than 20%. \\\n",
        "That’s on top of already-rising prices for battery-related raw materials, a result \\\n",
        "of supply-chain disruptions related to Covid and Russia’s invasion of Ukraine.\"\n",
        "\n",
        "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str5, text_pipeline)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGh7ZfBwRshi",
        "outputId": "3f845f85-06cd-45b1-a15b-b56fcdc6e860"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a Business news\n"
          ]
        }
      ]
    }
  ]
}